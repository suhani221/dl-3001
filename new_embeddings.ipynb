{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 05:53:17.122053: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from contextlib import contextmanager\n",
    "from sklearn.metrics import precision_recall_curve, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from collections import OrderedDict, defaultdict\n",
    "from itertools import repeat\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import linalg\n",
    "import sklearn\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import tqdm\n",
    "import shutil\n",
    "import queue\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import h5py\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "import wandb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from constants import CORTEX_REGIONS_DESCRIPTIONS, ELECTRODES_BROADMANN_MAPPING, BROADMANN_AREA_DESCRIPTIONS\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_electrode_descriptions(electrode_brodmann_map, brodmann_area_descrips):\n",
    "    \"\"\"map electrode names to brodmann areas descriptions and return a dictionary for electrode descriptions\n",
    "    \n",
    "    Args:\n",
    "        electrode_brodmann_map (dict): electrode to brodmann area mapping\n",
    "        brodmann_area_descrips (dict): brodmann area descriptions\n",
    "            \n",
    "    Returns:\n",
    "        dict: electrode descriptions\n",
    "    \"\"\"\n",
    "    electrode_descriptions = dict()\n",
    "    for electrode, brodmann_area in electrode_brodmann_map.items():\n",
    "        electrode_descriptions[electrode] = brodmann_area_descrips[brodmann_area]\n",
    "    return electrode_descriptions\n",
    "    \n",
    "import pandas as pd\n",
    "def preprocess_data(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    text_data = []\n",
    "    for file_path in data['filename']:\n",
    "        file_path = file_path.replace('\\\\', '/')\n",
    "        file_path = os.path.join('/home/user/Downloads/', file_path)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "        except (UnicodeDecodeError, FileNotFoundError):\n",
    "            text = ''\n",
    "        text_data.append(text)\n",
    "    data['text'] = text_data\n",
    "\n",
    "    seizure_types = ['cpsz', 'gnsz', 'fnsz', 'absz', 'tnsz', 'tcsz', 'spsz', 'mysz']\n",
    "    for seizure_type in seizure_types:\n",
    "        data[seizure_type] = data[seizure_type].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    return data, seizure_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_semantic_embeds():\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    \n",
    "    # Load Sentence Transformer\n",
    "    st_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    csv_file = '/DATA/seizure_count.csv'\n",
    "    data, seizure_types = preprocess_data(csv_file)\n",
    "    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Get embeddings for the text data\n",
    "    train_embeddings = st_model.encode(list(train_data['text']), convert_to_tensor=True)\n",
    "    val_embeddings = st_model.encode(list(val_data['text']), convert_to_tensor=True)\n",
    "    \n",
    "    # Encode descriptions\n",
    "    node_descriptions = get_electrode_descriptions(ELECTRODES_BROADMANN_MAPPING, BROADMANN_AREA_DESCRIPTIONS)\n",
    "    cortex_descriptions = CORTEX_REGIONS_DESCRIPTIONS.values()\n",
    "    descriptions = list(node_descriptions.values()) + list(cortex_descriptions)\n",
    "    \n",
    "    # Get embeddings for descriptions\n",
    "    description_embeddings = st_model.encode(descriptions, convert_to_tensor=True)\n",
    "    \n",
    "    return train_embeddings, val_embeddings, description_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c=get_semantic_embeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train embeddings: torch.Size([1138, 768])\n",
      "Size of validation embeddings: torch.Size([285, 768])\n",
      "Size of description embeddings: torch.Size([25, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of train embeddings:\", a.size())\n",
    "print(\"Size of validation embeddings:\", b.size())\n",
    "print(\"Size of description embeddings:\", c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0254, -0.0167,  0.0169,  ..., -0.0350, -0.0460, -0.0333],\n",
       "        [-0.0405, -0.0535,  0.0193,  ..., -0.0456, -0.0073, -0.0172],\n",
       "        [-0.0182, -0.0097,  0.0273,  ..., -0.0406, -0.0360, -0.0270],\n",
       "        ...,\n",
       "        [-0.0430, -0.0401,  0.0096,  ..., -0.0499, -0.0382, -0.0340],\n",
       "        [-0.0079, -0.0567,  0.0167,  ..., -0.0509, -0.0341, -0.0344],\n",
       "        [-0.0207, -0.0281,  0.0100,  ..., -0.0383, -0.0360, -0.0416]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0198, -0.0619, -0.0255,  ..., -0.0266,  0.0161, -0.0167],\n",
       "        [ 0.0135, -0.0590, -0.0275,  ..., -0.0193,  0.0202, -0.0129],\n",
       "        [ 0.0307, -0.0438, -0.0280,  ..., -0.0353,  0.0168, -0.0239],\n",
       "        ...,\n",
       "        [ 0.0021, -0.0331, -0.0372,  ..., -0.0159,  0.0293, -0.0088],\n",
       "        [ 0.0144, -0.0657, -0.0281,  ..., -0.0214,  0.0156, -0.0443],\n",
       "        [ 0.0160, -0.0452, -0.0007,  ..., -0.0107,  0.0222, -0.0350]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of aggregated train embeddings: torch.Size([25, 768])\n",
      "Size of aggregated validation embeddings: torch.Size([25, 768])\n",
      "Size of description embeddings: torch.Size([25, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def aggregate_embeddings(embeddings, num_nodes=25):\n",
    "\n",
    "    mean_embedding = torch.mean(embeddings, dim=0, keepdim=True)\n",
    "    aggregated_embeddings = mean_embedding.repeat(num_nodes, 1)\n",
    "    return aggregated_embeddings\n",
    "\n",
    "\n",
    "train_aggregated = aggregate_embeddings(a)\n",
    "val_aggregated = aggregate_embeddings(b)\n",
    "\n",
    "print(\"Size of aggregated train embeddings:\", train_aggregated.size())\n",
    "print(\"Size of aggregated validation embeddings:\", val_aggregated.size())\n",
    "print(\"Size of description embeddings:\", c.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined embeddings: torch.Size([3, 25, 768])\n"
     ]
    }
   ],
   "source": [
    "combined_embeddings = torch.stack([train_aggregated, val_aggregated, c], dim=0)\n",
    "\n",
    "print(\"Shape of combined embeddings:\", combined_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of average embeddings: torch.Size([25, 768])\n"
     ]
    }
   ],
   "source": [
    "average_embeddings = (train_aggregated + val_aggregated + c) / 3\n",
    "\n",
    "print(\"Shape of average embeddings:\", average_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_embeddings1= average_embeddings.cpu()  \n",
    "avg_embeddings_np = average_embeddings1.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('avg_embeddings.npy', avg_embeddings_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
